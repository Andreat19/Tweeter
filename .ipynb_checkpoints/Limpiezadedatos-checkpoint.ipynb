{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos tweets en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xml.dom import minidom\n",
    "from sklearn.datasets import load_files\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('twitter.txt', sep=\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['User - Description'] = df['User - Description'].astype(str)\n",
    "df['User - Time Zone'] = df['User - Time Zone'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar URL's, nombres de usuarios \n",
    "\n",
    "isURL = re.compile(r'http[s]?:// (?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', re.VERBOSE | re.IGNORECASE)\n",
    "isRTusername = re.compile(r'^RT+[\\s]+(@[\\w_]+:)',re.VERBOSE | re.IGNORECASE) #r'^RT+[\\s]+(@[\\w_]+:)'\n",
    "isEntity = re.compile(r'@[\\w_]+', re.VERBOSE | re.IGNORECASE) \n",
    "\n",
    "def clean_tweet(row):\n",
    "    row = isURL.sub(\"\",row)\n",
    "    row = isRTusername.sub(\"\",row)\n",
    "    row = isEntity.sub(\"\",row)\n",
    "    return row\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(lambda row:clean_tweet(row))\n",
    "\n",
    "\n",
    "\n",
    "# Eliminamos salto de linea\n",
    "df['Tweet'] = df['Tweet'].apply(lambda x: re.sub('\\n',\"\",x))\n",
    "df['User - Description'] = df['User - Description'].apply(lambda x: re.sub('\\n',\"\",x))\n",
    "\n",
    "\n",
    "# Limpiando signos de puntuación.\n",
    "def remove_punctuation ( text ):\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]', \"\", text)\n",
    "\n",
    "def normalize(city):\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "        (\"ü\", \"u\"),\n",
    "    )\n",
    "    for a, b in replacements:\n",
    "        city = city.replace(a, b).replace(a.upper(), b.upper()).capitalize().strip()\n",
    "    return  city\n",
    "\n",
    "columns_text = (['Tweet', 'User', 'User - Name', 'User - Description', 'User - Time Zone'])\n",
    "for i in columns_text:\n",
    "    df[i] = df[i].apply(lambda x: normalize(x))\n",
    "    df[i] = df[i].apply(lambda x: remove_punctuation(x))\n",
    "    \n",
    "\n",
    "# Cambiar a minusculas todas las palabras\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(lambda x: x.lower())\n",
    "df['User - Description'] = df['User - Description'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar Ciudades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitar signos de puntuación\n",
    "df['User - Location'].fillna('Colombia', inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sep_c(city):\n",
    "    city = city.split(',')\n",
    "    return city[0]\n",
    "\n",
    "def Sep_h(city):\n",
    "    city = city.split('-')\n",
    "    return city[0]\n",
    "\n",
    "def Sep_d(city):\n",
    "    return city.replace('\\t',\" \")\n",
    "\n",
    "def Sep_a(city):\n",
    "    return city.replace('\\n',\" \").replace('\\r',\" \")\n",
    "\n",
    "def Sep_e(city):\n",
    "    return city.replace('  ',\" \")\n",
    "\n",
    "import re\n",
    "\n",
    "def Medellin(city):\n",
    "    return  re.sub(r'(?is)Medell.+', 'Medellin', city)\n",
    "\n",
    "def Bogota(city):\n",
    "    return  re.sub(r'(?is)Bog.+', 'Bogota', city)\n",
    "\n",
    "def Popayan(city):\n",
    "    return  re.sub(r'(?is)Popay.+', 'Popayan', city)\n",
    "\n",
    "def Cali(city):\n",
    "    return city.replace('Santiago de cali',\"Cali\")\n",
    "def Ibague(city):\n",
    "    return city.replace('Colombia ibague tolima',\"Ibague\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h (txt):\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]', \"\", txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['User - Location'] = df['User - Location'].apply(lambda x : normalize(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Sep_d(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Sep_c(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Sep_h(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Medellin(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Bogota(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Cali(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Popayan(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Ibague(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Sep_e(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x: remove_punctuation(x))\n",
    "df['User - Location'] = df['User - Location'].apply(lambda x : Sep_a(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Colombia               14186\n",
       "Bogota                  3475\n",
       "Medellin                 922\n",
       "Rio de janeiro           514\n",
       "Cali                     465\n",
       "Venezuela                445\n",
       "Barranquilla             409\n",
       "Quito                    352\n",
       "Ecuador                  336\n",
       "Complexo do lins         279\n",
       "Guayaquil                268\n",
       "Ibague                   234\n",
       "Caracas                  212\n",
       "Bucaramanga              169\n",
       "Cartagena                134\n",
       "Mexico                   117\n",
       "Valledupar               117\n",
       "                         111\n",
       "Pereira                  103\n",
       "Miami                     95\n",
       "Santa marta               95\n",
       "021                       86\n",
       "Manizales                 82\n",
       "Villavicencio             81\n",
       "Buenos aires              73\n",
       "Argentina                 71\n",
       "Panama                    70\n",
       "Valle del cauca           68\n",
       "Cucuta                    68\n",
       "Monteria                  67\n",
       "Comunidad de madrid       63\n",
       "Lima                      63\n",
       "Brasil                    60\n",
       "Guayaquil                 55\n",
       "Popayan                   54\n",
       "So gonalo                 53\n",
       "Envigado                  50\n",
       "Antioquia                 50\n",
       "Quito                     48\n",
       "Rj                        48\n",
       "Madrid                    47\n",
       "Sincelejo                 44\n",
       "Paris                     43\n",
       "New york                  43\n",
       "Pasto                     41\n",
       "United states             39\n",
       "Chile                     39\n",
       "Na sua                    38\n",
       "Calle 59 no13             38\n",
       "Duque de caxias           37\n",
       "Name: User - Location, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['User - Location'].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Tweetsclean.csv', index = False, encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
